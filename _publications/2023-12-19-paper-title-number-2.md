---
title: "Exploring the Dialogue Comprehension Ability of Large Language Models"
collection: publications
permalink: /publication/2023-12-19-paper-title-number-2
excerpt: 'This study introduces a dual-assessment approach for large language models (LLMs), using dialogue summarization to evaluate factual consistency and derived factual questions to gauge comprehension, uncovering a notable error rate and proposing a multi-task fine-tuning strategy for improvement.'
date: 2023-12-19
venue: 'Arxiv'
paperurl: 'https://arxiv.org/abs/2311.07194'
citation: 'ng, X., Zhou, Y., &amp; Chen, J. (2023). Exploring the Dialogue Comprehension Ability of Large Language Models. ArXiv, abs/2311.07194.'
---
This study introduces a dual-assessment approach for large language models (LLMs), using dialogue summarization to evaluate factual consistency and derived factual questions to gauge comprehension, uncovering a notable error rate and proposing a multi-task fine-tuning strategy for improvement.

[Download paper here](https://arxiv.org/abs/2311.07194)

Recommended citation: ng, X., Zhou, Y., & Chen, J. (2023). Exploring the Dialogue Comprehension Ability of Large Language Models. ArXiv, abs/2311.07194.