---
title: "Exploring the Dialogue Comprehension Ability of Large Language Models"
collection: publications
permalink: /publication/2023-12-19-paper-title-number-2
excerpt: 'This study introduces a dual-assessment approach for large language models (LLMs), using dialogue summarization to evaluate factual consistency and derived factual questions to gauge comprehension, uncovering a notable error rate and proposing a multi-task fine-tuning strategy for improvement.'
date: 2023-12-19
venue: 'Arxiv'
paperurl: 'https://arxiv.org/abs/2311.07194'
citation: 'She S, Huang S, Wang X, et al. Exploring the Dialogue Comprehension Ability of Large Language Models[J]. arXiv preprint arXiv:2311.07194, 2023.'
---
This study introduces a dual-assessment approach for large language models (LLMs), using dialogue summarization to evaluate factual consistency and derived factual questions to gauge comprehension, uncovering a notable error rate and proposing a multi-task fine-tuning strategy for improvement.

[Download paper here](https://arxiv.org/abs/2311.07194)

Recommended citation: She S, Huang S, Wang X, et al. Exploring the Dialogue Comprehension Ability of Large Language Models[J]. arXiv preprint arXiv:2311.07194, 2023.