pub_date	title	venue	excerpt	citation	url_slug	paper_url
2022-11-19	CoP: Factual Inconsistency Detection by Controlling the Preference	AAAI2023	This paper proposes an interesting and novel idea for using tweaked model behavior as an evaluation for factual consistency. The paper demonstrates the SOTA performance on the corresponding task. [Code](https://github.com/NJUNLP/CoP) [文字解读](https://mp.weixin.qq.com/s/c3Wvp3b5hqN5CFvl2o92PQ) [Paper preprint](https://arxiv.org/abs/2212.01611)	She S, Geng X, Huang S, et al. CoP: Factual Inconsistency Detection by Controlling the Preference[J]. arXiv preprint arXiv:2212.01611, 2022. "Paper Title Number 1."	paper-title-number-1	https://arxiv.org/abs/2212.01611
2023-12	Improved Pseudo Data for Machine Translation Quality Estimation with Constrained Beam Search	EMNLP2023	The study introduces CBSQE, a method for generating more accurate pseudo data for machine translation quality estimation by using constrained beam search to differentiate between likely correct and incorrect translation segments, improving performance in both supervised and unsupervised settings.	Geng, X., Zhang, Y., Lai, Z., She, S., Zou, W., Tao, S., Yang, H., Chen, J., & Huang, S. (2023). Improved Pseudo Data for Machine Translation Quality Estimation with Constrained Beam Search. Conference on Empirical Methods in Natural Language Processing.	paper-title-number-2	https://aclanthology.org/2023.emnlp-main.764.pdf
2023-12-19	Exploring the Dialogue Comprehension Ability of Large Language Models	Arxiv	This study introduces a dual-assessment approach for large language models (LLMs), using dialogue summarization to evaluate factual consistency and derived factual questions to gauge comprehension, uncovering a notable error rate and proposing a multi-task fine-tuning strategy for improvement.	She S, Huang S, Wang X, et al. Exploring the Dialogue Comprehension Ability of Large Language Models[J]. arXiv preprint arXiv:2311.07194, 2023.	paper-title-number-2	https://arxiv.org/abs/2311.07194