pub_date	title	venue	excerpt	citation	url_slug	paper_url
2022-11-19	CoP: Factual Inconsistency Detection by Controlling the Preference	AAAI2023	This paper proposes an interesting and novel idea for using tweaked model behavior as an evaluation for factual consistency. The paper demonstrates the SOTA performance on the corresponding task. [Code](https://github.com/NJUNLP/CoP) [文字解读](https://mp.weixin.qq.com/s/c3Wvp3b5hqN5CFvl2o92PQ) [Paper preprint](https://arxiv.org/abs/2212.01611)	She S, Geng X, Huang S, et al. CoP: Factual Inconsistency Detection by Controlling the Preference[J]. arXiv preprint arXiv:2212.01611, 2022. "Paper Title Number 1."	paper-title-number-1	https://arxiv.org/abs/2212.01611
2023-12-19	Exploring the Dialogue Comprehension Ability of Large Language Models	Arxiv	This study introduces a dual-assessment approach for large language models (LLMs), using dialogue summarization to evaluate factual consistency and derived factual questions to gauge comprehension, uncovering a notable error rate and proposing a multi-task fine-tuning strategy for improvement.	ng, X., Zhou, Y., & Chen, J. (2023). Exploring the Dialogue Comprehension Ability of Large Language Models. ArXiv, abs/2311.07194.	paper-title-number-2	https://arxiv.org/abs/2311.07194